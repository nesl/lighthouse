\section{Evaluation}
\label{sec:eval}



In this section we evaluate the need for static checking of resource
management and the practical utility of our approach for statically
detecting resource management errors in sensor-network software.  
%
Our evaluation uses all code in the public CVS archive of the SOS
operating system.
%
SOS applications are made up of small user written components called
modules that can be combined into larger programs.  
%
These modules run on top of the SOS kernel and are developed using an
API supplied by this kernel.



\subsection{Quantifying Dynamic Memory Usage in SOS}



First we measure the prevalence of dynamic resource management within
sensor network systems.  
%
As we have seen, in TinyOS this corresponds to the buffer swapping
protocol within messaging stacks, and in SOS this corresponds to dynamic
memory management.



Focusing on SOS, we quantify the usage in SOS modules of the kernel's
API for memory manipulation.
%
This includes the functions used to allocate (\code{ker\_malloc}), free
(\code{ker\_free}), and transfer ownership (\code{SOS\_MSG\_RELEASE} and
\code{ker\_msg\_take\_data}) of blocks of memory.



The SOS CVS head from October 2006 contains 36 modules totaling 5824 source 
lines of code.  
%
Within this sample there are 178 lines of code
calling a kernel function that manipulates memory, or one such function call
for every 33 source lines of code.  
%
A look at all historic version of all
SOS modules reveals that this frequency has not changed significantly
over time.  
%
These findings indicate that dynamic memory management has been
and continues to be an important part of SOS applications.



\subsection{Validating SOS End-User Modules}



Given that memory is frequently manipulated as a resource in SOS
programs, our next study aimed to answer the following questions:
%
\begin{itemize}
%
\item Do programmers have problems properly managing dynamic memory in
SOS?
%
\item Does the analysis and associated checker described in this paper
help statically identify those problems?
%
\end{itemize}



To address these questions we ran Lighthouse on all end-user modules
from SOS to demonstrate how it would fit into the ordinary SOS
development cycle.  
%
We applied the checker to every historic version of each user module
included in the SOS CVS repository that would compile for the
\code{mica2} target.  
%
The 48 available modules resulted in a total of 213 unique versions
totaling 28042 source lines of code.
%
The specification file used for this analysis included 9 functions to
analyze user modules and 17 more functions to enable analysis of the SOS
kernel.
%
Additionally, 9 custom function specifications were added to analyze
module functions wrapping the underlying memory manipulation API.
%
Finally, a change to the core SOS API from the summer of 2006 required
changing the value of a flag constant in 6 module versions.



\begin{table}
\caption{Warnings in SOS user modules}
%
\label{tab:module}
\centering 
\begin{tabular}{| l | r |}
    \hline 
    Verified memory leaks identified by analysis & 8 \\
    \hline
    False memory leaks identified by analysis & 8 \\
    \hline 
    Verified dangling pointers identified by analysis & 0 \\
    \hline 
    False dangling pointers identified by analysis & 9 \\
    \hline 
\end{tabular} 
%
\end{table}



Of the 213 modules analyzed, 13 of the modules generated Lighthouse
warnings for a total of 25 warnings.
%
For this analysis, we only consider the first occurrence of a particular
warning within a module, even if the warning lasts through multiple
consecutive versions of the module.  
%
Each warning was examined by hand and classified as an actual error or a
false positive; the results are presented in Table~\ref{tab:module}.  
%
Eight of the warnings were real memory leaks in the code.  This is
impressive since the CVS repository houses well-tested and stable
applications.
%
The 17 remaining warnings were further classified to better understand
the sources of imprecision in Lighthouse.  



\smallskip\noindent{\bf Memory leak false positives.}



False positives from memory leaks came from two different sources of
imprecision in our must-alias analysis.
%
First, the analysis is intraprocedural, so it must conservatively assume
that procedure calls can change the contents of pointers passed as
actual arguments.  
%
Therefore, any must-alias information for these pointers is invalidated
across procedure calls, leading to five false positives.
%
The analysis can easily rank these as probable false positives if the
end user wishes to see more likely errors first.  
%
The other three false positives were the result of linked-list data
structures that the must-alias analysis is unable to precisely reason
about.  



\smallskip\noindent{\bf Dangling pointer false positives.}



The nine dangling pointer false positives result from limitations of the
may-alias analysis.  
%
Improvements could be gained by adding field and flow sensitivity to
this analysis.
%
Although these properties generally make an alias analysis difficult to
scale, sensor network applications may be small enough due to resource
constraints that we can leverage these sophisticated techniques in a
practical manner.


\subsection{Validating the SOS Kernel}



\begin{table}
\caption{Warnings in the SOS kernel}
%
\label{tab:kernel}
\centering 
\begin{tabular}{| l | r |}
    \hline 
    Verified memory leaks identified by analysis & 2 \\
    \hline
    False memory leaks identified by analysis & 22 \\
    \hline 
    Verified dangling pointers identified by analysis & 0 \\
    \hline 
    False dangling pointers identified by analysis & 11 \\
    \hline 
\end{tabular} 
%
\end{table}


We ran a similar experiment on all code that comprises the current SOS
kernel for the \code{mica2} target.  
%
This configuration consists of 9223 source lines of code and required
analyzing 40 source files.  
%
Of these 13 files generated at least one warning for a total of 35
warnings.  
%
A detailed breakdown of these warnings is provided in
Table~\ref{tab:kernel}.



The two actual errors occurred in functions that released ownership of
some memory to the caller via a formal parameter, except under specific
conditions in which an error code is returned.
%
The callers of these functions were treating them as unconditionally
releasing memory, without checking the return value.  
%
Lighthouse flags each function as being in error, since there exist
paths to the function exit that fail to release memory to the formal
parameter.  
%
It would be interesting to augment our ownership annotations to support
the notion of {\em conditional} ownership transfer.  
%
In such a setting, our analysis could allow the functions to be
considered correct but then require each caller to check the error code
before assuming that it owns the memory pointed to by the parameter.




While the user modules studied above resulted in approximately one false
positive for every 1650 source lines of code, the SOS kernel had
approximately one false positive for every 270 source lines of code.  
%
This increase in the rate of false positives is to be expected, since
the kernel includes a significant amount of low-level code that does not
conform to the ownership discipline meant to be obeyed by user modules.
%
For example, the function \code{ker\_msg\_take\_data} is specified to
return a new memory buffer,  but Lighthouse warns that no such memory is
returned.  
%
This is because the function's implementation directly accesses the
internal data structures of the SOS memory manager to return a pointer
to dynamically allocated data, rather than calling a function from the
SOS API like \code{ker\_malloc}.


